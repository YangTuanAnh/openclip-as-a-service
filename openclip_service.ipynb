{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VjUa-7Y6Kk"
      },
      "source": [
        "# OpenCLIP Embedding Service (Colab)\n",
        "\n",
        "Run a minimal FastAPI service to serve text embeddings on GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4k5XCBY6Ko",
        "outputId": "1232bd52-370c-4f08-f26f-b5c950a2db1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q uv pyngrok\n",
        "!uv pip install -q fastapi uvicorn open-clip-torch torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "9d6215be6dca48dfb671ccaca9905280",
            "856c38f5f32e49189e454d83b5854740",
            "dd46133a92834a08b4d71fa9dffde6f6",
            "d1b906e716734945946cc4cb90b30d98",
            "37250d3e65f343969f290685f6e7aacf",
            "da034490b85e44b9a6cdeed1457eaf79",
            "bf39a50a68274e90b7cf677dcccc56ec",
            "a3bd3c84af5f471b8411b23657c77c4c",
            "1e79358896b94a4bad2fe7fc9a4e3c46",
            "4c6d262c95054ddfa42f58832757250b",
            "f8da2d8565bf4ec685c36be228260ff4",
            "95b41b65fef745a2976978c9a654335d",
            "0c55c4e149264b0aad93aa306a8ecc68",
            "5182ac6cc4214a869ca12da3a097733a",
            "dfa751f073b248b88e848d900b92b4ee",
            "dc8814b61cf648ba8d37a0b75394cd87",
            "fd12c0c161d64e84b40a02601e9df546",
            "b33077d2eba84e01a2bd622091c73a7e",
            "d23ab3cd3bd34c8a9a48311f5ead3479",
            "4ff47ea19781465ba825a8f4ba783341",
            "e58050f1d8ce4adc87fde32b2411625b",
            "acda497fec58404e809b2942ddbef2a3"
          ]
        },
        "id": "Kix_z_9LY6Kp",
        "outputId": "fc53b44c-20c1-406f-9b21-fbcdee62c851"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d6215be6dca48dfb671ccaca9905280",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_config.json:   0%|          | 0.00/600 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b41b65fef745a2976978c9a654335d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/1.79G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import open_clip\n",
        "\n",
        "MODEL_ID = 'hf-hub:openai/clip-vit-base-patch32'\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(MODEL_ID, device=DEVICE)\n",
        "model.eval()\n",
        "model = model.to(torch.float16)\n",
        "tokenizer = open_clip.get_tokenizer(MODEL_ID)\n",
        "\n",
        "def l2_normalize(t: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.nn.functional.normalize(t, p=2, dim=-1)\n",
        "\n",
        "class EmbedRequest(BaseModel):\n",
        "    texts: list[str]\n",
        "    normalize: bool = True\n",
        "\n",
        "class EmbedResponse(BaseModel):\n",
        "    embeddings: list[list[float]]\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "@app.post('/embed', response_model=EmbedResponse)\n",
        "def embed(req: EmbedRequest):\n",
        "    tokens = tokenizer(req.texts).to(DEVICE)\n",
        "    with torch.inference_mode():\n",
        "        feats = model.encode_text(tokens)\n",
        "        if req.normalize:\n",
        "            feats = l2_normalize(feats)\n",
        "        feats = feats.detach().float().cpu().numpy()\n",
        "    return EmbedResponse(embeddings=feats.tolist())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJyLMDiMY6Kr",
        "outputId": "8c9a1a7b-9ad7-441e-ac34-a33e7a8c348a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [895]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://cbc4ae08de71.ngrok-free.app\n",
            "POST https://cbc4ae08de71.ngrok-free.app/embed\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "from pyngrok import ngrok, conf\n",
        "import threading\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "# Start uvicorn in background\n",
        "config = uvicorn.Config(app, host='0.0.0.0', port=8000, log_level='info')\n",
        "server = uvicorn.Server(config)\n",
        "thread = threading.Thread(target=server.run, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Expose via ngrok\n",
        "tunnel = ngrok.connect(8000, \"http\")\n",
        "print(\"Public URL:\", tunnel.public_url)\n",
        "print(\"POST\", tunnel.public_url + \"/embed\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
